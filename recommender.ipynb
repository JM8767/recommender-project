{"cells":[{"cell_type":"code","execution_count":154,"metadata":{"execution":{"iopub.execute_input":"2024-07-08T05:18:43.320314Z","iopub.status.busy":"2024-07-08T05:18:43.319424Z","iopub.status.idle":"2024-07-08T05:20:02.536072Z","shell.execute_reply":"2024-07-08T05:20:02.534981Z","shell.execute_reply.started":"2024-07-08T05:18:43.320279Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["   MovieID                               Title                        Genres\n","0        1                    Toy Story (1995)   Animation|Children's|Comedy\n","1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n","2        3             Grumpier Old Men (1995)                Comedy|Romance\n","3        4            Waiting to Exhale (1995)                  Comedy|Drama\n","4        5  Father of the Bride Part II (1995)                        Comedy\n","   UserID  MovieID  Rating  Timestamp\n","0       1     1193       5  978300760\n","1       1      661       3  978302109\n","2       1      914       3  978301968\n","3       1     3408       4  978300275\n","4       1     2355       5  978824291\n","   UserID Gender  Age  Occupation Zip-code\n","0       1      F    1          10    48067\n","1       2      M   56          16    70072\n","2       3      M   25          15    55117\n","3       4      M   45           7    02460\n","4       5      M   25          20    55455\n","      nconst      primaryName birthYear deathYear  \\\n","0  nm0000001     Fred Astaire      1899      1987   \n","1  nm0000002    Lauren Bacall      1924      2014   \n","2  nm0000003  Brigitte Bardot      1934        \\N   \n","3  nm0000004     John Belushi      1949      1982   \n","4  nm0000005   Ingmar Bergman      1918      2007   \n","\n","                    primaryProfession                           knownForTitles  \n","0        actor,miscellaneous,producer  tt0072308,tt0050419,tt0053137,tt0027125  \n","1  actress,soundtrack,archive_footage  tt0037382,tt0075213,tt0117057,tt0038355  \n","2   actress,music_department,producer  tt0057345,tt0049189,tt0056404,tt0054452  \n","3       actor,writer,music_department  tt0072562,tt0077975,tt0080455,tt0078723  \n","4               writer,director,actor  tt0050986,tt0083922,tt0050976,tt0069467  \n","      tconst titleType            primaryTitle           originalTitle  \\\n","0  tt0000001     short              Carmencita              Carmencita   \n","1  tt0000002     short  Le clown et ses chiens  Le clown et ses chiens   \n","2  tt0000003     short          Pauvre Pierrot          Pauvre Pierrot   \n","3  tt0000004     short             Un bon bock             Un bon bock   \n","4  tt0000005     short        Blacksmith Scene        Blacksmith Scene   \n","\n","  isAdult startYear endYear runtimeMinutes                    genres  \n","0       0      1894      \\N              1         Documentary,Short  \n","1       0      1892      \\N              5           Animation,Short  \n","2       0      1892      \\N              5  Animation,Comedy,Romance  \n","3       0      1892      \\N             12           Animation,Short  \n","4       0      1893      \\N              1              Comedy,Short  \n"]}],"source":["# Data Collection and Preprocessing\n","\n","import pandas as pd\n","import difflib\n","\n","# Define the file paths\n","movies_file = 'ml-1m/movies.dat'\n","ratings_file = 'ml-1m/ratings.dat'\n","users_file = 'ml-1m/users.dat'\n","\n","# Load the datasets\n","movies = pd.read_csv(movies_file, delimiter='::', engine='python', names=['MovieID', 'Title', 'Genres'], encoding='latin1')\n","ratings = pd.read_csv(ratings_file, delimiter='::', engine='python', names=['UserID', 'MovieID', 'Rating', 'Timestamp'], encoding='latin1')\n","users = pd.read_csv(users_file, delimiter='::', engine='python', names=['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code'], encoding='latin1')\n","\n","\n","name_basics = pd.read_csv('name.basics.tsv', sep='\\t', low_memory=False)\n","title_basics = pd.read_csv('title.basics.tsv', sep='\\t', low_memory=False)\n","\n","# Display the first few rows of each dataset\n","print(movies.head())\n","print(ratings.head())\n","print(users.head())\n","print(name_basics.head())\n","print(title_basics.head())"]},{"cell_type":"code","execution_count":156,"metadata":{"execution":{"iopub.execute_input":"2024-07-08T05:20:15.408977Z","iopub.status.busy":"2024-07-08T05:20:15.408614Z","iopub.status.idle":"2024-07-08T05:20:31.933249Z","shell.execute_reply":"2024-07-08T05:20:31.932251Z","shell.execute_reply.started":"2024-07-08T05:20:15.408949Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["   UserID  MovieID  Rating\n","0       1      260     4.0\n","1       1      588     4.0\n","2       1      595     5.0\n","3       1     1022     5.0\n","4       1     1028     5.0\n","Number of unique ratings: 223646\n"]}],"source":["# Feature Engineering\n","\n","# Extract the year from the MovieLens title and standardize titles\n","movies['Year'] = movies['Title'].str.extract(r'\\((\\d{4})\\)', expand=False)\n","movies['Title'] = movies['Title'].str.replace(r'\\(\\d{4}\\)', '').str.strip().str.lower()\n","\n","# Standardize IMDb titles and remove NaNs\n","title_basics['primaryTitle'] = title_basics['primaryTitle'].str.lower().fillna('')\n","title_basics['originalTitle'] = title_basics['originalTitle'].str.lower().fillna('')\n","\n","merged_data_primary = pd.merge(movies, title_basics, left_on='Title', right_on='primaryTitle', how='inner')\n","\n","if merged_data_primary.empty:\n","    merged_data_original = pd.merge(movies, title_basics, left_on='Title', right_on='originalTitle', how='inner')\n","else:\n","    merged_data_original = pd.DataFrame()\n","\n","merged_data = pd.concat([merged_data_primary, merged_data_original]).drop_duplicates()\n","\n","# Merge with ratings\n","merged_ratings = pd.merge(ratings, merged_data, on='MovieID', how='inner')\n","\n","# Remove duplicates\n","aggregated_ratings = merged_ratings.groupby(['UserID', 'MovieID']).agg({'Rating': 'mean'}).reset_index()\n","\n","aggregated_ratings.to_csv('aggregated_ratings.csv', index=False)\n","\n","print(aggregated_ratings.head())\n","print(f\"Number of unique ratings: {len(aggregated_ratings)}\")"]},{"cell_type":"code","execution_count":161,"metadata":{"execution":{"iopub.execute_input":"2024-07-08T05:25:01.375413Z","iopub.status.busy":"2024-07-08T05:25:01.374813Z","iopub.status.idle":"2024-07-08T05:25:01.477959Z","shell.execute_reply":"2024-07-08T05:25:01.477004Z","shell.execute_reply.started":"2024-07-08T05:25:01.375381Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Movie features scaled shape: (519, 1)\n"]}],"source":["# Feature Engineering\n","\n","# Handle NaNs\n","merged_data['Genres'] = merged_data['Genres'].fillna('').astype(str)\n","\n","#Genres\n","merged_data['Genres'] = merged_data['Genres'].str.split('|')\n","mlb = pd.get_dummies(merged_data['Genres'].apply(pd.Series).stack()).groupby(level=0).sum()\n","merged_data_with_genres = pd.concat([merged_data, mlb], axis=1)\n","\n","# Generate movie features\n","movie_features = merged_data_with_genres.drop(['Title', 'Year', 'Genres', 'primaryTitle', 'originalTitle', 'tconst', 'titleType', 'isAdult', 'startYear', 'endYear', 'runtimeMinutes', 'genres'], axis=1)\n","\n","numeric_movie_features = movie_features.select_dtypes(include=[np.number])\n","\n","numeric_movie_features = numeric_movie_features[numeric_movie_features['MovieID'].isin(aggregated_ratings['MovieID'])]\n","\n","# Aggregate user features\n","user_features = aggregated_ratings.groupby('UserID').mean().reset_index()\n","\n","# Ensure only numeric columns are selected for scaling\n","numeric_user_features = user_features.select_dtypes(include=[np.number])\n","\n","# Normalize the features\n","scaler_movie = StandardScaler()\n","movie_features_scaled = scaler_movie.fit_transform(numeric_movie_features.drop('MovieID', axis=1))\n","\n","scaler_user = StandardScaler()\n","user_features_scaled = scaler_user.fit_transform(numeric_user_features.drop('UserID', axis=1))\n","\n","# Scale the ratings\n","scaler_rating = MinMaxScaler((-1, 1))\n","aggregated_ratings['Rating'] = scaler_rating.fit_transform(aggregated_ratings['Rating'].values.reshape(-1, 1))\n","\n","print(\"Movie features scaled shape:\", movie_features_scaled.shape)"]},{"cell_type":"code","execution_count":162,"metadata":{"execution":{"iopub.execute_input":"2024-07-08T05:25:06.647522Z","iopub.status.busy":"2024-07-08T05:25:06.646630Z","iopub.status.idle":"2024-07-08T05:25:06.714560Z","shell.execute_reply":"2024-07-08T05:25:06.713661Z","shell.execute_reply.started":"2024-07-08T05:25:06.647489Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_43\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional_43\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_45      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ input_layer_46      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ sequential_23       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,536</span> │ input_layer_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │ input_layer_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dot_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n","│                     │                   │            │ sequential_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]… │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_45      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ input_layer_46      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ sequential_23       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │     \u001b[38;5;34m37,536\u001b[0m │ input_layer_45[\u001b[38;5;34m0\u001b[0m… │\n","│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │ input_layer_46[\u001b[38;5;34m0\u001b[0m… │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dot_7 (\u001b[38;5;33mDot\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ sequential_23[\u001b[38;5;34m0\u001b[0m]… │\n","│                     │                   │            │ sequential_23[\u001b[38;5;34m1\u001b[0m]… │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">37,536</span> (146.62 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m37,536\u001b[0m (146.62 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">37,536</span> (146.62 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m37,536\u001b[0m (146.62 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["# Model Development\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import Layer\n","\n","class L2Normalization(Layer):\n","    def call(self, inputs):\n","        return tf.linalg.l2_normalize(inputs, axis=1)\n","\n","# Create user and movie models with the custom L2 normalization layer\n","num_outputs = 32\n","\n","# Movie model\n","item_NN = tf.keras.models.Sequential([\n","    tf.keras.layers.Dense(256, activation='relu', input_shape=(1,)),\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    tf.keras.layers.Dense(num_outputs),\n","    L2Normalization()\n","])\n","\n","# Create the movie input and point to the base network\n","input_item = tf.keras.layers.Input(shape=(1,))\n","vm = item_NN(input_item)\n","\n","input_item2 = tf.keras.layers.Input(shape=(1,))\n","vm2 = item_NN(input_item2)\n","\n","output = tf.keras.layers.Dot(axes=1)([vm, vm2])\n","\n","model = tf.keras.Model([input_item, input_item2], output)\n","\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='mean_squared_error')\n","\n","model.summary()"]},{"cell_type":"code","execution_count":163,"metadata":{"execution":{"iopub.execute_input":"2024-07-08T05:25:10.020848Z","iopub.status.busy":"2024-07-08T05:25:10.020197Z","iopub.status.idle":"2024-07-08T05:25:10.078617Z","shell.execute_reply":"2024-07-08T05:25:10.077626Z","shell.execute_reply.started":"2024-07-08T05:25:10.020816Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of common MovieIDs: 330\n","Shape of movie_features_filtered before handling duplicates: (519, 2)\n","Shape of aggregated_ratings_filtered before handling duplicates: (223646, 3)\n","Duplicate MovieIDs in movie_features_filtered: 189\n","Duplicate MovieIDs in aggregated_ratings_filtered: 223316\n","Shape of movie_features_filtered after handling duplicates: (330, 2)\n","Shape of aggregated_ratings_filtered after handling duplicates: (330, 2)\n","MovieIDs aligned: True\n","Shape of X_movie: (330, 1)\n","Shape of y: (330,)\n","Assertion passed: X_movie and y have the same number of samples.\n"]}],"source":["# Find common MovieIDs\n","common_movie_ids = set(numeric_movie_features['MovieID']) & set(aggregated_ratings['MovieID'])\n","print(f\"Number of common MovieIDs: {len(common_movie_ids)}\")\n","\n","# Filter both dataframes to include only these common MovieIDs\n","movie_features_filtered = numeric_movie_features[numeric_movie_features['MovieID'].isin(common_movie_ids)]\n","aggregated_ratings_filtered = aggregated_ratings[aggregated_ratings['MovieID'].isin(common_movie_ids)]\n","\n","print(f\"Shape of movie_features_filtered before handling duplicates: {movie_features_filtered.shape}\")\n","print(f\"Shape of aggregated_ratings_filtered before handling duplicates: {aggregated_ratings_filtered.shape}\")\n","\n","# Check for duplicates\n","print(f\"Duplicate MovieIDs in movie_features_filtered: {movie_features_filtered['MovieID'].duplicated().sum()}\")\n","print(f\"Duplicate MovieIDs in aggregated_ratings_filtered: {aggregated_ratings_filtered['MovieID'].duplicated().sum()}\")\n","\n","movie_features_filtered = movie_features_filtered.groupby('MovieID').first().reset_index()\n","\n","aggregated_ratings_filtered = aggregated_ratings_filtered.groupby('MovieID')['Rating'].mean().reset_index()\n","\n","print(f\"Shape of movie_features_filtered after handling duplicates: {movie_features_filtered.shape}\")\n","print(f\"Shape of aggregated_ratings_filtered after handling duplicates: {aggregated_ratings_filtered.shape}\")\n","\n","# Sort dataframes by MovieID\n","movie_features_filtered = movie_features_filtered.sort_values('MovieID').reset_index(drop=True)\n","aggregated_ratings_filtered = aggregated_ratings_filtered.sort_values('MovieID').reset_index(drop=True)\n","\n","print(f\"MovieIDs aligned: {(movie_features_filtered['MovieID'] == aggregated_ratings_filtered['MovieID']).all()}\")\n","\n","# Now create X_movie and y\n","X_movie = movie_features_filtered.drop('MovieID', axis=1).values\n","y = aggregated_ratings_filtered['Rating'].values\n","\n","print(f\"Shape of X_movie: {X_movie.shape}\")\n","print(f\"Shape of y: {y.shape}\")\n","\n","try:\n","    assert X_movie.shape[0] == len(y), \"Inconsistent number of samples between X_movie and y\"\n","    print(\"Assertion passed: X_movie and y have the same number of samples.\")\n","except AssertionError as e:\n","    print(f\"Assertion failed: {e}\")\n","    print(f\"X_movie shape: {X_movie.shape}, y length: {len(y)}\")"]},{"cell_type":"code","execution_count":164,"metadata":{"execution":{"iopub.execute_input":"2024-07-08T05:25:13.173213Z","iopub.status.busy":"2024-07-08T05:25:13.172850Z","iopub.status.idle":"2024-07-08T05:25:16.428051Z","shell.execute_reply":"2024-07-08T05:25:16.427144Z","shell.execute_reply.started":"2024-07-08T05:25:13.173182Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/2\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 259ms/step - loss: 0.8635 - val_loss: 0.9274\n","Epoch 2/2\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9064 - val_loss: 0.9274\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x7912d6965bd0>"]},"execution_count":164,"metadata":{},"output_type":"execute_result"}],"source":["# Split into training and testing sets\n","X_movie_train, X_movie_test, y_train, y_test = train_test_split(X_movie, y, test_size=0.2, random_state=42)\n","\n","# Fit the model\n","model.fit([X_movie_train, X_movie_train], y_train, epochs=2, batch_size=64, validation_data=([X_movie_test, X_movie_test], y_test))"]},{"cell_type":"code","execution_count":165,"metadata":{"execution":{"iopub.execute_input":"2024-07-08T05:25:18.996623Z","iopub.status.busy":"2024-07-08T05:25:18.996261Z","iopub.status.idle":"2024-07-08T05:25:19.696222Z","shell.execute_reply":"2024-07-08T05:25:19.695198Z","shell.execute_reply.started":"2024-07-08T05:25:18.996594Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n","Train RMSE: 1.8566486289616995\n","Test RMSE: 1.926040433254923\n"]}],"source":["from sklearn.metrics import mean_squared_error\n","\n","# Evaluate the model\n","y_pred_train = model.predict([X_movie_train, X_movie_train])\n","y_pred_test = model.predict([X_movie_test, X_movie_test])\n","\n","# Convert scaled ratings back to original scale\n","y_train_original = scaler_rating.inverse_transform(y_train.reshape(-1, 1))\n","y_test_original = scaler_rating.inverse_transform(y_test.reshape(-1, 1))\n","y_pred_train_original = scaler_rating.inverse_transform(y_pred_train)\n","y_pred_test_original = scaler_rating.inverse_transform(y_pred_test)\n","\n","# Calculate RMSE\n","rmse_train = np.sqrt(mean_squared_error(y_train_original, y_pred_train_original))\n","rmse_test = np.sqrt(mean_squared_error(y_test_original, y_pred_test_original))\n","\n","print(f\"Train RMSE: {rmse_train}\")\n","print(f\"Test RMSE: {rmse_test}\")"]},{"cell_type":"code","execution_count":166,"metadata":{"execution":{"iopub.execute_input":"2024-07-08T05:25:21.696093Z","iopub.status.busy":"2024-07-08T05:25:21.695761Z","iopub.status.idle":"2024-07-08T05:25:21.701998Z","shell.execute_reply":"2024-07-08T05:25:21.700902Z","shell.execute_reply.started":"2024-07-08T05:25:21.696067Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Valid MovieIDs for Testing: [2, 10, 16, 18, 34, 39, 44, 69, 70, 76, 95, 111, 112, 145, 153, 160, 172, 173, 181, 193, 208, 216, 223, 235, 253, 260, 288, 292, 316, 330, 356, 379, 380, 390, 434, 441, 442, 456, 464, 480, 485, 504, 519, 532, 541, 586, 587, 588, 589, 592, 595, 596, 600, 648, 653, 673, 714, 798, 810, 837, 849, 891, 899, 903, 904, 910, 918, 920, 923, 931, 951, 953, 968, 973, 1022, 1028, 1029, 1030, 1032, 1036, 1080, 1089, 1097, 1101, 1126, 1129, 1193, 1196, 1198, 1199, 1200, 1203, 1207, 1210, 1213, 1214, 1219, 1225, 1227, 1252, 1255, 1256, 1259, 1265, 1270, 1274, 1275, 1276, 1278, 1282, 1287, 1288, 1291, 1304, 1311, 1336, 1339, 1340, 1341, 1342, 1345, 1359, 1367, 1372, 1376, 1377, 1387, 1388, 1389, 1394, 1407, 1438, 1483, 1518, 1552, 1562, 1566, 1573, 1580, 1587, 1591, 1599, 1655, 1673, 1681, 1688, 1704, 1707, 1721, 1748, 1754, 1760, 1762, 1805, 1809, 1831, 1835, 1882, 1884, 1895, 1907, 1945, 1954, 1955, 1956, 1958, 1961, 1964, 1973, 1974, 1975, 1977, 1978, 1979, 1982, 1983, 1985, 1986, 1987, 1988, 1991, 1992, 1994, 1998, 2000, 2003, 2004, 2011, 2014, 2021, 2052, 2060, 2087, 2088, 2093, 2099, 2105, 2113, 2115, 2119, 2122, 2143, 2144, 2148, 2149, 2160, 2164, 2167, 2174, 2176, 2186, 2193, 2273, 2291, 2316, 2325, 2327, 2328, 2361, 2366, 2367, 2368, 2377, 2387, 2398, 2403, 2413, 2416, 2429, 2430, 2431, 2461, 2464, 2465, 2513, 2517, 2527, 2529, 2555, 2587, 2606, 2640, 2641, 2642, 2643, 2644, 2645, 2646, 2647, 2648, 2651, 2653, 2656, 2661, 2663, 2664, 2706, 2716, 2717, 2722, 2723, 2768, 2782, 2787, 2791, 2797, 2808, 2858, 2872, 2878, 2901, 2902, 2903, 2916, 2918, 2947, 2953, 2959, 2985, 2986, 2989, 2997, 3016, 3018, 3024, 3026, 3034, 3081, 3087, 3101, 3113, 3160, 3168, 3175, 3210, 3213, 3246, 3259, 3264, 3286, 3305, 3409, 3438, 3440, 3448, 3471, 3476, 3479, 3489, 3490, 3527, 3535, 3578, 3593, 3633, 3660, 3663, 3665, 3671, 3676, 3696, 3697, 3699, 3702, 3704, 3727, 3793, 3843, 3877, 3917]\n"]}],"source":["# Select example MovieIDs for testing\n","valid_movie_ids_for_testing = list(movie_id_to_index_map.keys())\n","\n","print(\"Valid MovieIDs for Testing:\", valid_movie_ids_for_testing)"]},{"cell_type":"code","execution_count":167,"metadata":{"execution":{"iopub.execute_input":"2024-07-08T05:25:23.870995Z","iopub.status.busy":"2024-07-08T05:25:23.870072Z","iopub.status.idle":"2024-07-08T05:25:23.899571Z","shell.execute_reply":"2024-07-08T05:25:23.898662Z","shell.execute_reply.started":"2024-07-08T05:25:23.870952Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted ratings range:\n","Min: 5.0\n","Max: 5.0\n","Mean: 5.0\n","Median: 5.0\n","\n","Top 10 Recommended Movies:\n","               Title  PredictedRating\n","0      casino (1995)              5.0\n","1  four rooms (1995)              5.0\n","2        babe (1995)              5.0\n","3    clueless (1995)              5.0\n","\n","Bottom 5 Recommended Movies:\n","Empty DataFrame\n","Columns: [Title, PredictedRating]\n","Index: []\n"]}],"source":["# Recommendation Algorithm / Evaluation\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","\n","# Function to get the index of a movie from its MovieID\n","def get_movie_index(movie_id, movie_features_merged):\n","    movie_row = movie_features_merged[movie_features_merged['MovieID'] == movie_id]\n","    if movie_row.empty:\n","        print(f\"MovieID {movie_id} not found in the dataset\")\n","        return None\n","    return movie_row.index[0]\n","\n","def recommend_movies_based_on_two_liked(movie_id1, movie_id2, model, movie_features_merged, movie_features_scaled):\n","    index1 = get_movie_index(movie_id1, movie_features_merged)\n","    index2 = get_movie_index(movie_id2, movie_features_merged)\n","    \n","    if index1 is None or index2 is None:\n","        return pd.DataFrame()\n","\n","    movie1_features = movie_features_scaled[index1].reshape(1, -1)\n","    movie2_features = movie_features_scaled[index2].reshape(1, -1)\n","    \n","    # Aggregate the features of the two liked movies\n","    combined_features = (movie1_features + movie2_features) / 2\n","    \n","    # Predict ratings for all movies\n","    all_predictions_scaled = model.predict([np.tile(combined_features, (movie_features_scaled.shape[0], 1)), movie_features_scaled])\n","    \n","    print(\"Raw predictions (first 5):\", all_predictions_scaled[:5])\n","    print(\"Min prediction:\", np.min(all_predictions_scaled))\n","    print(\"Max prediction:\", np.max(all_predictions_scaled))\n","    \n","    # If using MinMaxScaler, adjust the inverse_transform\n","    if isinstance(scaler_rating, MinMaxScaler):\n","        all_predictions = scaler_rating.inverse_transform(all_predictions_scaled.reshape(-1, 1)).flatten()\n","    else:\n","        all_predictions = scaler_rating.inverse_transform(all_predictions_scaled)\n","    \n","    return all_predictions\n","\n","\n","# After getting the recommendations\n","if len(predicted_ratings) > 0:\n","    print(\"Predicted ratings range:\")\n","    print(\"Min:\", np.min(predicted_ratings))\n","    print(\"Max:\", np.max(predicted_ratings))\n","    print(\"Mean:\", np.mean(predicted_ratings))\n","    print(\"Median:\", np.median(predicted_ratings))\n","\n","    # Create a DataFrame for the predicted ratings\n","    predicted_ratings_df = pd.DataFrame({'MovieID': movie_features_merged['MovieID'], 'PredictedRating': predicted_ratings})\n","\n","    # Exclude the movies that are already liked\n","    predicted_ratings_df = predicted_ratings_df[~predicted_ratings_df['MovieID'].isin([movie_id1, movie_id2])]\n","\n","    # Get the top 10 recommended movies\n","    top_recommendations = predicted_ratings_df.sort_values(by='PredictedRating', ascending=False).head(10)\n","\n","    # Merge with the movies DataFrame to get movie titles\n","    top_recommendations = pd.merge(top_recommendations, movies[['MovieID', 'Title']], on='MovieID')\n","\n","    print(\"\\nTop 10 Recommended Movies:\")\n","    print(top_recommendations[['Title', 'PredictedRating']])\n","\n","    # Print bottom 5 recommendations for comparison\n","    bottom_recommendations = predicted_ratings_df.sort_values(by='PredictedRating', ascending=True).head(5)\n","    bottom_recommendations = pd.merge(bottom_recommendations, movies[['MovieID', 'Title']], on='MovieID')\n","    print(\"\\nBottom 5 Recommended Movies:\")\n","    print(bottom_recommendations[['Title', 'PredictedRating']])"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5350840,"sourceId":8900597,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
